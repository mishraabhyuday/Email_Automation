{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pdfminer\n",
    "import glob\n",
    "import docx2txt\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing of Documents/pdf\n",
    "#### First of all conversion of various formats to txt format should be done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting :\n",
    "##### 1.pdf -> text\n",
    "##### 2.docx file -> text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.PDF to txt conversion using text using pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "def pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. DOC to txt conversion using  docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def docx_to_txt(path):\n",
    "    return  docx2txt.process(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making a list of all pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpdf = glob.glob(r'C:\\Users\\mishr\\OneDrive\\Desktop\\Data_Science\\sicuremi\\CVs for code assessment\\*.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making a list of all doc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldoc = glob.glob(r'C:\\Users\\mishr\\OneDrive\\Desktop\\Data_Science\\sicuremi\\CVs for code assessment\\*.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumeAkshaySangtani.pdf',\n",
       " 'C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumeHuseinVasanwala.pdf',\n",
       " 'C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumeJaswinderjeetsinghJass.pdf',\n",
       " 'C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumeKanishkSingh.pdf',\n",
       " 'C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumeMohammedShaik.pdf',\n",
       " 'C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumeNehaChauhan.pdf',\n",
       " 'C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumeOmDevSingh.pdf',\n",
       " 'C:\\\\Users\\\\mishr\\\\OneDrive\\\\Desktop\\\\Data_Science\\\\sicuremi\\\\CVs for code assessment\\\\ResumePallavKulkarni.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract email form the text\n",
    "Since we notice that an email has '@' in it.\n",
    "Also in the string obtained from the preprocessed pdf and doc convertors have '\\n' in from as well as at the back of the individual email id.We seperate accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email(txt):\n",
    "\n",
    "    ln  = re.split('[\\n :]',txt)\n",
    "    for each in ln:\n",
    "        if '@' in each and len(each)>2:\n",
    "            return each;\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\mishr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mishr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mishr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\mishr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Error loading word: Package 'word' not found in index\n"
     ]
    }
   ],
   "source": [
    "#using nltk NER(named entity recognition)\n",
    "\n",
    "def extract_name(txt):\n",
    "    \n",
    "    for sent in nltk.sent_tokenize(txt):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
    "                name= ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
    "                return name\n",
    "\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_list = []\n",
    "name_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting email from pdf\n",
    "for x in lpdf:\n",
    "    txt = pdf_to_txt(str(x)).replace('\\t',' ')\n",
    "    email_list.append(extract_email(txt))\n",
    "    \n",
    "#extracting email from docx\n",
    "for x in ldoc:\n",
    "    txt = docx_to_txt(str(x)).replace('\\t',' ')\n",
    "    email_list.append(extract_email(txt))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akshaysangtani5_vyj@indeedemail.com',\n",
       " 'hussain.vasanwala533fojb@gmail.com',\n",
       " 'jasskomaljass@gmail.com',\n",
       " 'singhkanishk001@gmail.com',\n",
       " 'mohammedthaseen8_zha@indeedemail.com',\n",
       " 'nehachauhan85_r7e@indeedemail.com',\n",
       " 'devsingh640@gmail.com',\n",
       " 'kulkarni15pallav@gmail.com',\n",
       " 'deepalisalwan@gmail.com',\n",
       " 'sujeet.gdas@gmail.com']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting names from pdf\n",
    "for x in lpdf:\n",
    "    txt = pdf_to_txt(str(x))\n",
    "    name_list.append(extract_name(txt))\n",
    "    \n",
    "#extracting names from docx\n",
    "for x in ldoc:\n",
    "    txt = docx_to_txt(str(x))\n",
    "    name_list.append((extract_name(txt)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Akshay',\n",
       " 'Husein',\n",
       " 'Mitter',\n",
       " 'Kanishk',\n",
       " 'Mohammed',\n",
       " 'Neha',\n",
       " 'Faridabad',\n",
       " 'Data',\n",
       " 'Deepali Salwan Deepali Salwan',\n",
       " 'Sujeet']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
